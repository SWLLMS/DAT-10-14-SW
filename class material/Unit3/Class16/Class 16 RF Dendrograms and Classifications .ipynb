{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 16: Agenda\n",
    "   \n",
    "   1. Lasso/Ridge Review\n",
    "   2. RF: \n",
    "       a. Dendrograms\n",
    "       b. Feature Importance\n",
    "   3. Classification\n",
    "       a. Logistic Regression (SVM Support Vector Machine was written in the 90s in C)\n",
    "           i. Sigmoid\n",
    "           ii. Api\n",
    "       b. Random Forest Cluster\n",
    "   4. Grid Search?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/swllms/DAT-10-14-SW/class material/Unit3/Data/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       8.326673e-17\n",
       "ZN         3.466704e-16\n",
       "INDUS     -3.016965e-15\n",
       "CHAS       3.999875e-16\n",
       "NOX        3.167427e-15\n",
       "RM        -1.258809e-14\n",
       "AGE       -1.158274e-15\n",
       "DIS        7.308603e-16\n",
       "RAD       -1.068535e-15\n",
       "TAX        6.534079e-16\n",
       "PTRATIO   -1.084420e-14\n",
       "B          8.117354e-15\n",
       "LSTAT     -6.494585e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUST Standardize before you run! \n",
    "X = (X - X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        2.71542789, -0.        , -0.        , -0.        , -0.        ,\n",
       "       -1.34428304,  0.18036988, -3.54677609])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If coef is set 0 (Lasso) it is functionally removed from your data set better for very large messy data. Ridge REDUCES to near 0 and more conservative. \n",
    "\n",
    "Coef mean the same as basic linear reg. think of this as a form of regression that chooses what features to focus on for the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_term = alpha * np.sum(np.abs(lasso.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.86856908757778"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_term #this is the penalty term! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace (-4, 4, 9) #Sensible range of testing Alpha, this block tests alpha\n",
    "lasso_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.set_params(alpha=alpha)\n",
    "    scores = cross_val_score(estimator=lasso, X=X, y=y, cv=10)\n",
    "    lasso_scores.append((np.mean(scores), alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.20262012278999347, 0.0001),\n",
       " (0.20343535169466956, 0.001),\n",
       " (0.21144430759385185, 0.01),\n",
       " (0.2407890782467927, 0.1),\n",
       " (0.1807548507575551, 1.0),\n",
       " (-1.2860830508551744, 10.0),\n",
       " (-1.2860830508551744, 100.0),\n",
       " (-1.2860830508551744, 1000.0),\n",
       " (-1.2860830508551744, 10000.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_scores\n",
    "#0.1 would have been the best version for alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrests\n",
    "\n",
    "Tend to be a bit more accurate then linear models but DS were saying that it was not clear the information provided by ensembles. Feature importance and Dendrograms are used to figure out what causes what. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swllms/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04415707, 0.00060074, 0.00499874, 0.00050157, 0.01755777,\n",
       "       0.37504468, 0.01591818, 0.07291872, 0.00376635, 0.01501034,\n",
       "       0.01391251, 0.01132919, 0.42428412])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.DataFrame({\n",
    "    'Featrues': X.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers will sum up to a 1 and the closest thing your will get to a coef but not the same thing, all numbers are positive.\n",
    "\n",
    "Indirectly tells you the realative importance of each value by looking at score (r squared value) and randomly rearrange the colmn value anc compare the new score to your model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Featrues</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.424284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>0.375045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>0.072919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.044157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>0.017558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.015918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>0.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.013913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.011329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.004999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Featrues  Importance\n",
       "12    LSTAT    0.424284\n",
       "5        RM    0.375045\n",
       "7       DIS    0.072919\n",
       "0      CRIM    0.044157\n",
       "4       NOX    0.017558\n",
       "6       AGE    0.015918\n",
       "9       TAX    0.015010\n",
       "10  PTRATIO    0.013913\n",
       "11        B    0.011329\n",
       "2     INDUS    0.004999\n",
       "8       RAD    0.003766\n",
       "1        ZN    0.000601\n",
       "3      CHAS    0.000502"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9769181552281025"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create trees based on thresholds of importance. you can see more details doing the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.424284\n",
       "5     0.799329\n",
       "7     0.872248\n",
       "0     0.916405\n",
       "4     0.933962\n",
       "6     0.949881\n",
       "9     0.964891\n",
       "10    0.978803\n",
       "11    0.990133\n",
       "2     0.995131\n",
       "8     0.998898\n",
       "1     0.999498\n",
       "3     1.000000\n",
       "Name: Importance, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats['Importance'].cumsum() #cumilative sum to show you what is critical from %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendrograms is jonathans favorite topic and hard to find details online. \n",
    "Pairs perfectly with Random Forest! \n",
    "\n",
    "Nothing that is done automatically so takes a few extra steps. \n",
    "\n",
    "Pearson's Correlation = Linear Association\n",
    "Spearmans Correlation = Rank Correlation \n",
    "\n",
    "See seperate notebook in prompts section. Will be posted later tonight 12/11/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifications\n",
    "\n",
    "Predicting discreet categories instead of continious numbers \n",
    "ie: boy/girl, green/blue/black\n",
    "\n",
    "Logistic Regression works like linear model Using Sigmoid function takes continuous numbers and tranforms them into prob between 0 and 1 1/1+e**-x e**-x = y=MX+b\n",
    "\n",
    "The results are the odds that this events that this will happen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 +np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid (0) \n",
    "# 50 % Chance this would happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990889488055994"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/swllms/Desktop/retonightsexitticket/train.csv')\n",
    "test = pd.read_csv('/Users/swllms/Desktop/retonightsexitticket/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:, ['Sex', 'Pclass']]\n",
    "y_train = train['Survived']\n",
    "X_test = test.loc[:, ['Sex', 'Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=['Sex', 'Pclass'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['Sex', 'Pclass'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop first removes the first column! Always a good idea when you one hot incode with minimal impact to your data or with catagorical data\n",
    "\n",
    "Reduces the number of colms and gives your a better picture of the impact. \n",
    "\n",
    "The first column that your drop gets wrapped up in the inercept term (the prediction that you make if all other information is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params() \n",
    "#C is alpha, alpha is C however it is inverted (0.1 = 100)\n",
    "#higher vlaues singal lowest strength or regularization and vice versa\n",
    "#penalty default is set to L2 (Ridge and Lasso are bulit in you can specify l1 or l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)\n",
    "#0 = passagner died\n",
    "#1 = passanger lived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.20028547, 0.79971453],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.75093089, 0.24906911],\n",
       "       [0.60521334, 0.39478666],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.41462909, 0.58537091],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.11295975, 0.88704025],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527],\n",
       "       [0.89503473, 0.10496527]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test) #Must also do this step\n",
    "#first number predicts the chance that number was 0, second predicts if they lived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10496527, 0.58537091, 0.24906911, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.58537091, 0.24906911, 0.58537091, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.88704025, 0.24906911, 0.88704025,\n",
       "       0.79971453, 0.24906911, 0.10496527, 0.58537091, 0.58537091,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.39478666, 0.88704025,\n",
       "       0.10496527, 0.88704025, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.24906911, 0.24906911, 0.58537091, 0.58537091, 0.39478666,\n",
       "       0.10496527, 0.58537091, 0.58537091, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.79971453, 0.88704025,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.88704025, 0.58537091,\n",
       "       0.39478666, 0.24906911, 0.79971453, 0.88704025, 0.24906911,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.88704025,\n",
       "       0.10496527, 0.24906911, 0.10496527, 0.58537091, 0.39478666,\n",
       "       0.79971453, 0.58537091, 0.39478666, 0.39478666, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.39478666, 0.88704025,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.24906911, 0.58537091,\n",
       "       0.10496527, 0.39478666, 0.39478666, 0.10496527, 0.24906911,\n",
       "       0.10496527, 0.58537091, 0.58537091, 0.58537091, 0.24906911,\n",
       "       0.58537091, 0.10496527, 0.88704025, 0.10496527, 0.39478666,\n",
       "       0.10496527, 0.88704025, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.88704025, 0.24906911, 0.10496527, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.24906911,\n",
       "       0.24906911, 0.58537091, 0.88704025, 0.58537091, 0.88704025,\n",
       "       0.10496527, 0.10496527, 0.58537091, 0.39478666, 0.79971453,\n",
       "       0.79971453, 0.10496527, 0.88704025, 0.10496527, 0.10496527,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.24906911, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.58537091, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.58537091, 0.10496527,\n",
       "       0.58537091, 0.88704025, 0.39478666, 0.24906911, 0.39478666,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.39478666, 0.24906911,\n",
       "       0.88704025, 0.10496527, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.10496527, 0.88704025, 0.58537091, 0.39478666, 0.58537091,\n",
       "       0.58537091, 0.10496527, 0.79971453, 0.10496527, 0.24906911,\n",
       "       0.58537091, 0.39478666, 0.10496527, 0.88704025, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.10496527,\n",
       "       0.79971453, 0.79971453, 0.39478666, 0.79971453, 0.88704025,\n",
       "       0.24906911, 0.39478666, 0.88704025, 0.10496527, 0.88704025,\n",
       "       0.24906911, 0.79971453, 0.10496527, 0.58537091, 0.24906911,\n",
       "       0.24906911, 0.39478666, 0.10496527, 0.24906911, 0.24906911,\n",
       "       0.10496527, 0.39478666, 0.58537091, 0.24906911, 0.58537091,\n",
       "       0.58537091, 0.10496527, 0.39478666, 0.79971453, 0.24906911,\n",
       "       0.39478666, 0.58537091, 0.24906911, 0.88704025, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.79971453, 0.58537091,\n",
       "       0.39478666, 0.58537091, 0.39478666, 0.88704025, 0.10496527,\n",
       "       0.79971453, 0.10496527, 0.79971453, 0.10496527, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.10496527, 0.24906911,\n",
       "       0.24906911, 0.88704025, 0.10496527, 0.10496527, 0.39478666,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.79971453, 0.88704025,\n",
       "       0.88704025, 0.79971453, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.79971453, 0.24906911, 0.79971453, 0.58537091,\n",
       "       0.79971453, 0.10496527, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.79971453, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.79971453, 0.58537091, 0.24906911,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.58537091, 0.10496527,\n",
       "       0.79971453, 0.24906911, 0.24906911, 0.24906911, 0.24906911,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.58537091, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.58537091, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.79971453, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.24906911, 0.24906911, 0.10496527, 0.58537091,\n",
       "       0.88704025, 0.39478666, 0.10496527, 0.39478666, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.58537091, 0.88704025,\n",
       "       0.58537091, 0.39478666, 0.24906911, 0.10496527, 0.24906911,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.39478666, 0.88704025,\n",
       "       0.10496527, 0.79971453, 0.39478666, 0.24906911, 0.24906911,\n",
       "       0.79971453, 0.39478666, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.39478666, 0.24906911, 0.10496527, 0.24906911, 0.10496527,\n",
       "       0.24906911, 0.10496527, 0.10496527, 0.88704025, 0.10496527,\n",
       "       0.58537091, 0.24906911, 0.58537091, 0.24906911, 0.79971453,\n",
       "       0.88704025, 0.24906911, 0.24906911, 0.24906911, 0.58537091,\n",
       "       0.39478666, 0.88704025, 0.10496527, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.79971453, 0.79971453, 0.10496527, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.88704025, 0.24906911,\n",
       "       0.24906911, 0.88704025, 0.39478666, 0.24906911, 0.88704025,\n",
       "       0.88704025, 0.58537091, 0.24906911, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.58537091, 0.58537091, 0.24906911,\n",
       "       0.79971453, 0.10496527, 0.24906911, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.88704025, 0.10496527, 0.24906911, 0.10496527,\n",
       "       0.88704025, 0.10496527, 0.88704025, 0.10496527, 0.10496527,\n",
       "       0.88704025, 0.24906911, 0.88704025, 0.39478666, 0.39478666,\n",
       "       0.24906911, 0.24906911, 0.39478666, 0.58537091, 0.58537091,\n",
       "       0.58537091, 0.88704025, 0.58537091, 0.10496527, 0.88704025,\n",
       "       0.10496527, 0.10496527, 0.10496527])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06085883])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.48809433, -0.67634771, -1.7159975 ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>-2.488094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>-0.676348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-1.715997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable    Weight\n",
       "0  Sex_male -2.488094\n",
       "1  Pclass_2 -0.676348\n",
       "2  Pclass_3 -1.715997"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = pd.DataFrame({\n",
    "    'Variable': X_train.columns, \n",
    "    'Weight': logreg.coef_[0]\n",
    "})\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.384511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-1.103583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.427235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -2.143233\n",
       "1    2.060859\n",
       "2    0.344861\n",
       "3    2.060859\n",
       "4   -2.143233\n",
       "5   -2.143233\n",
       "6   -0.427235\n",
       "7   -2.143233\n",
       "8    0.344861\n",
       "9    1.384511\n",
       "10   0.344861\n",
       "11   2.060859\n",
       "12  -2.143233\n",
       "13  -2.143233\n",
       "14   0.344861\n",
       "15   1.384511\n",
       "16  -2.143233\n",
       "17  -1.103583\n",
       "18   0.344861\n",
       "19   0.344861\n",
       "20  -1.103583\n",
       "21  -1.103583\n",
       "22   0.344861\n",
       "23  -0.427235\n",
       "24   0.344861\n",
       "25   0.344861\n",
       "26  -2.143233\n",
       "27  -0.427235\n",
       "28   0.344861\n",
       "29  -2.143233\n",
       "..        ...\n",
       "861 -1.103583\n",
       "862  2.060859\n",
       "863  0.344861\n",
       "864 -1.103583\n",
       "865  1.384511\n",
       "866  1.384511\n",
       "867 -0.427235\n",
       "868 -2.143233\n",
       "869 -2.143233\n",
       "870 -2.143233\n",
       "871  2.060859\n",
       "872 -0.427235\n",
       "873 -2.143233\n",
       "874  1.384511\n",
       "875  0.344861\n",
       "876 -2.143233\n",
       "877 -2.143233\n",
       "878 -2.143233\n",
       "879  2.060859\n",
       "880  1.384511\n",
       "881 -2.143233\n",
       "882  0.344861\n",
       "883 -1.103583\n",
       "884 -2.143233\n",
       "885  0.344861\n",
       "886 -1.103583\n",
       "887  2.060859\n",
       "888  0.344861\n",
       "889 -0.427235\n",
       "890 -2.143233\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = X_train.dot(logreg.coef_.T) + logreg.intercept_\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0.799715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.249069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.394787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.104965\n",
       "1    0.887040\n",
       "2    0.585371\n",
       "3    0.887040\n",
       "4    0.104965\n",
       "5    0.104965\n",
       "6    0.394787\n",
       "7    0.104965\n",
       "8    0.585371\n",
       "9    0.799715\n",
       "10   0.585371\n",
       "11   0.887040\n",
       "12   0.104965\n",
       "13   0.104965\n",
       "14   0.585371\n",
       "15   0.799715\n",
       "16   0.104965\n",
       "17   0.249069\n",
       "18   0.585371\n",
       "19   0.585371\n",
       "20   0.249069\n",
       "21   0.249069\n",
       "22   0.585371\n",
       "23   0.394787\n",
       "24   0.585371\n",
       "25   0.585371\n",
       "26   0.104965\n",
       "27   0.394787\n",
       "28   0.585371\n",
       "29   0.104965\n",
       "..        ...\n",
       "861  0.249069\n",
       "862  0.887040\n",
       "863  0.585371\n",
       "864  0.249069\n",
       "865  0.799715\n",
       "866  0.799715\n",
       "867  0.394787\n",
       "868  0.104965\n",
       "869  0.104965\n",
       "870  0.104965\n",
       "871  0.887040\n",
       "872  0.394787\n",
       "873  0.104965\n",
       "874  0.799715\n",
       "875  0.585371\n",
       "876  0.104965\n",
       "877  0.104965\n",
       "878  0.104965\n",
       "879  0.887040\n",
       "880  0.799715\n",
       "881  0.104965\n",
       "882  0.585371\n",
       "883  0.249069\n",
       "884  0.104965\n",
       "885  0.585371\n",
       "886  0.249069\n",
       "887  0.887040\n",
       "888  0.585371\n",
       "889  0.394787\n",
       "890  0.104965\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid (output)\n",
    "#the probablity! #Ground zero of nural networks\n",
    "#natural range for sigmoid is - 7 to 7\n",
    "#REMEMBER: higher vlaues singal lowest strength or regularization and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifer\n",
    "\n",
    "Works in a manner that almost idential to their Regressor Counterpart\n",
    "Classify a sample by takin a majority vote of the each leave balue \n",
    "Basic syntax is the same\n",
    "\n",
    "Takes the majority vote of that leaf\n",
    "ie if 10 people are on a leaf and 6 lived and one died it would spit out that you would have a prob of 60% \n",
    "\n",
    "All other information for random trees remains the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swllms/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72745472, 0.0267825 , 0.24576278])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See slides for the remainder of the notes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
